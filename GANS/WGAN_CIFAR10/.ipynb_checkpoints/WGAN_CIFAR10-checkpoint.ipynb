{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tensorflow.python.keras.regularizers import L2\n",
    "from WGAN_GP import WGAN_GP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size):\n",
    "    @ tf.function\n",
    "    def parse_files(filename):\n",
    "        image_string = tf.io.read_file(filename)\n",
    "        image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "        image = tf.cast(image_decoded, tf.float32) / 127.5 - 1\n",
    "        return image\n",
    "\n",
    "    # ds= tf.data.Dataset.list_files('C:/Users/alans/tensorflow_datasets/celeb_a/img_align_celeba/*.jpg', shuffle=False)\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    x_train = x_train[np.where(y_train[:,0] == 2)]\n",
    "    plt.imshow(x_train[50,:,:,:])\n",
    "    x_train = x_train / 127.5 - 1\n",
    "    x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(x_train).shuffle(1000).batch(batch_size)\n",
    "    # ds = ds.shuffle(len(ds)).map(parse_files)\n",
    "    # ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    # ds = ds.prefetch(buffer_size=batch_size)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "ds = load_data(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_relu(x, useRelu=True):\n",
    "    fx = layers.BatchNormalization()(x)\n",
    "    if useRelu:\n",
    "        fx = layers.LeakyReLU(0.3)(fx)\n",
    "    return fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x, filterNumb, kernel_size, strides=1, padding='same', use_bias=True):\n",
    "    fx = layers.Conv2D(filterNumb, kernel_size, strides, padding=padding,\n",
    "                    use_bias=use_bias)(x)\n",
    "    return fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filterNumb, isPooling=False):\n",
    "    strides = 1\n",
    "    shortcut = x\n",
    "    bn_x = bn_relu(x)\n",
    "    if isPooling:\n",
    "        strides = (2,2)\n",
    "        shortcut = conv(bn_x, filterNumb, kernel_size=1, strides=strides)\n",
    "    fx = conv(bn_x, filterNumb, kernel_size=3, strides=strides)\n",
    "    fx = bn_relu(fx)\n",
    "    fx = conv(fx, filterNumb, kernel_size=3)\n",
    "    out = layers.Add()([shortcut, fx]) # skip\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_transpose(model, kernels, strides, activation=None):\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.3))\n",
    "    model.add(layers.Conv2DTranspose(kernels, (3, 3), strides=strides, padding='same', use_bias=False))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(gan_model, seed=None, isShow=True, isSaveFile=False):\n",
    "    grid_size = (2,2)\n",
    "    w, h = grid_size\n",
    "    img_count = w * h\n",
    "    if seed is None:\n",
    "        seed = tf.random.normal(shape=(4, 1, 1, gan_model.seed_size))\n",
    "    fake_img_batch = gan_model.generator(test_seed, training=False)\n",
    "    fig = plt.figure(figsize=grid_size, dpi=70)\n",
    "    fig.set_figheight(4)\n",
    "    fig.set_figwidth(4)\n",
    "    for i in range(img_count):\n",
    "        plt.subplot(w, h, i+1)\n",
    "        img = tf.cast(fake_img_batch[i, :, :, :] * 127.5 + 127.5, dtype='uint8')\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    if isShow: \n",
    "        plt.show()\n",
    "    if isSaveFile:\n",
    "        if not os.path.exists('./Results'):\n",
    "            os.makedirs('./Results')\n",
    "        plt.savefig('./Results/{:06d}.png'.format(gan_model.dis_opt.iterations.numpy()))\n",
    "        \n",
    "# models\n",
    "def create_generator(seed_size):\n",
    "    inputs = layers.Input(shape=(1, 1, seed_size))\n",
    "    hx = layers.UpSampling2D(size=(4,4))(inputs)\n",
    "    hx = conv(hx, seed_size, kernel_size=4)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    hx = conv(hx, seed_size, kernel_size=3)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    hx = layers.UpSampling2D(size=(2,2))(hx)\n",
    "    hx = conv(hx, 64, kernel_size=3)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    hx = conv(hx, 64, kernel_size=3)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    hx = layers.UpSampling2D(size=(2,2))(hx)\n",
    "    hx = conv(hx, 32, kernel_size=3)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    hx = conv(hx, 32, kernel_size=3)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    hx = layers.UpSampling2D(size=(2,2))(hx) \n",
    "    hx = conv(hx, 16, kernel_size=3)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    hx = conv(hx, 16, kernel_size=3)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    outputs = conv(hx, 3, kernel_size=1)\n",
    "    outputs = layers.Activation('tanh')(outputs)\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"Generator\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    inputs = layers.Input(shape=(32, 32, 3))\n",
    "    hx = conv(inputs, 16, kernel_size=1)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    hx = conv(hx, 16, kernel_size=3)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    hx = conv(hx, 32, kernel_size=3, strides=2)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    hx = conv(hx, 32, kernel_size=3)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    hx = conv(hx, 64, kernel_size=3, strides=2)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    hx = conv(hx, 64, kernel_size=3)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    hx = conv(hx, 128, kernel_size=3, strides=2)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    hx = conv(hx, 128, kernel_size=3)\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    hx = conv(hx, 128, kernel_size=4, strides=4, padding='valid')\n",
    "    hx = layers.LeakyReLU(0.3)(hx)\n",
    "    outputs = layers.Dense(1)(hx)\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"Discriminator\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_WGAN_GP(seed_size, gen_lr, dis_lr, dis_extra_steps):\n",
    "    generator = create_generator(seed_size)\n",
    "    discriminator = create_discriminator()\n",
    "    gen_opt = tf.keras.optimizers.Adam(learning_rate=gen_lr)\n",
    "    dis_opt = tf.keras.optimizers.Adam(learning_rate=dis_lr)\n",
    "    gen_loss_fn = lambda fake_pred: -tf.reduce_mean(fake_pred)\n",
    "    dis_loss_fn = lambda real_pred, fake_pred: tf.reduce_mean(fake_pred) - tf.reduce_mean(real_pred)\n",
    "    gan_model = WGAN_GP(discriminator, generator, seed_size, dis_extra_steps=dis_extra_steps)\n",
    "    gan_model.compile(gen_opt, dis_opt, gen_loss_fn, dis_loss_fn)\n",
    "    return gan_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "seed_size = 128\n",
    "gen_lr = 0.0001\n",
    "dis_lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seed = tf.random.normal(shape=(4, 1, 1, seed_size))\n",
    "gan_model = create_WGAN_GP(seed_size, gen_lr, dis_lr, dis_extra_steps=5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%% ======= training ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('./tb_logs', ignore_errors=True)\n",
    "shutil.rmtree('./Results', ignore_errors=True)\n",
    "class GANMonitor(tf.keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        if batch % 200 == 0:\n",
    "            generate_image(self.model, seed=test_seed, isShow=False, isSaveFile=True)\n",
    "        \n",
    "mon_cb = GANMonitor()\n",
    "save_cb = tf.keras.callbacks.ModelCheckpoint('./Checkpoints/', verbose=1)\n",
    "board_cb = tf.keras.callbacks.TensorBoard( log_dir='./tb_logs/', write_images=True, update_freq='batch') \n",
    "gan_model.fit(ds, epochs=epochs, shuffle=True, callbacks=[board_cb, mon_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%% ======= testing ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif():\n",
    "    with imageio.get_writer('./Results/result.gif', mode='I') as writer:\n",
    "        filenames = glob.glob('./Results/*.png')\n",
    "        filenames = sorted(filenames)\n",
    "        for filename in filenames:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "create_gif()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

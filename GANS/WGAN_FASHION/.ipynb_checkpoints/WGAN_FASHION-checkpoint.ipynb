{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.regularizers import L2\n",
    "from WGAN_GP import WGAN_GP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size):\n",
    "    (train_images, train_labels), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "    train_images = train_images.reshape(train_images.shape + (1,)).astype('float32') / 127.5 - 1\n",
    "    ds = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "    ds = ds.shuffle(len(ds)).batch(batch_size, drop_remainder=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_relu(x, useRelu=True):\n",
    "    fx = layers.BatchNormalization()(x)\n",
    "    if useRelu:\n",
    "        fx = layers.LeakyReLU(0.2)(fx)\n",
    "    return fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x, filterNumb, kernel_size, strides=1, use_bias=True):\n",
    "    fx = layers.Conv2D(filterNumb, kernel_size, strides, padding='same', \n",
    "                    use_bias=use_bias, kernel_regularizer=L2(0.01))(x)\n",
    "    return fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filterNumb, isPooling=False):\n",
    "    strides = 1\n",
    "    shortcut = x\n",
    "    bn_x = bn_relu(x)\n",
    "    if isPooling:\n",
    "        strides = (2,2)\n",
    "        shortcut = conv(bn_x, filterNumb, kernel_size=1, strides=strides)\n",
    "    fx = conv(bn_x, filterNumb, kernel_size=3, strides=strides)\n",
    "    fx = bn_relu(fx)\n",
    "    fx = conv(fx, filterNumb, kernel_size=3)\n",
    "    out = layers.Add()([shortcut, fx]) # skip\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_transpose(model, kernels, strides, activation=None):\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    model.add(layers.Conv2DTranspose(kernels, (3, 3), strides=strides, padding='same', use_bias=False))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(gan_model, seed=None, isShow=True, isSaveFile=False):\n",
    "    grid_size = (3,3)\n",
    "    w, h = grid_size\n",
    "    img_count = w * h\n",
    "    if seed is None:\n",
    "        seed = tf.random.normal(shape=(9, gan_model.seed_size))\n",
    "    fake_img_batch = gan_model.generator(test_seed, training=False)\n",
    "    fig = plt.figure(figsize=grid_size, dpi=100)\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(5)\n",
    "    for i in range(img_count):\n",
    "        plt.subplot(w, h, i+1)\n",
    "        plt.imshow(fake_img_batch[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    if isShow: \n",
    "        plt.show()\n",
    "    if isSaveFile:\n",
    "        if not os.path.exists('./Results'):\n",
    "            os.makedirs('./Results')\n",
    "        plt.savefig('./Results/{:06d}.png'.format(gan_model.dis_opt.iterations.numpy()))\n",
    "        \n",
    "# models\n",
    "def create_generator(seed_size):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(4*4*256, use_bias=False, input_shape=(seed_size,)))\n",
    "    model.add(layers.Reshape((4, 4, 256)))\n",
    "    assert model.output_shape == (None, 4, 4, 256)\n",
    "    conv_transpose(model, 128, (2,2))\n",
    "    assert model.output_shape == (None, 8, 8, 128)\n",
    "    conv_transpose(model, 64, (2,2))\n",
    "    assert model.output_shape == (None, 16, 16, 64)\n",
    "    conv_transpose(model, 1, (2,2))\n",
    "    assert model.output_shape == (None, 32, 32, 1)\n",
    "    \n",
    "    model.add(layers.Cropping2D((2,2)))\n",
    "    model.add(layers.Activation('tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    inputs = layers.Input(shape=(28,28,1)) # 28*28\n",
    "    hx = layers.ZeroPadding2D((2,2))(inputs) # 32*32\n",
    "    hx = conv(hx, 32, kernel_size=5, strides=2)\n",
    "    hx = layers.LeakyReLU(0.2)(hx)\n",
    "    hx = layers.Dropout(0.3)(hx)\n",
    "    hx = conv(hx, 64, kernel_size=5, strides=2)\n",
    "    hx = layers.LeakyReLU(0.2)(hx)\n",
    "    hx = layers.Dropout(0.3)(hx)\n",
    "    hx = conv(hx, 128, kernel_size=5, strides=2)\n",
    "    hx = layers.LeakyReLU(0.2)(hx)\n",
    "    hx = layers.Dropout(0.2)(hx)\n",
    "    hx = layers.Flatten()(hx)\n",
    "    hx = layers.Dense(512)(hx)\n",
    "    hx = layers.LeakyReLU(0.2)(hx)\n",
    "    hx = layers.Dropout(0.2)(hx)\n",
    "    outputs = layers.Dense(1)(hx)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_WGAN_GP(seed_size, gen_lr, dis_lr, dis_extra_steps):\n",
    "    generator = create_generator(seed_size)\n",
    "    discriminator = create_discriminator()\n",
    "    gen_opt = tf.keras.optimizers.RMSprop(learning_rate=gen_lr)\n",
    "    dis_opt = tf.keras.optimizers.RMSprop(learning_rate=dis_lr)\n",
    "    gen_loss_fn = lambda fake_pred: -tf.reduce_mean(fake_pred)\n",
    "    dis_loss_fn = lambda real_pred, fake_pred: tf.reduce_mean(fake_pred) - tf.reduce_mean(real_pred)\n",
    "    gan_model = WGAN_GP(discriminator, generator, seed_size, dis_extra_steps=dis_extra_steps)\n",
    "    gan_model.compile(gen_opt, dis_opt, gen_loss_fn, dis_loss_fn)\n",
    "    return gan_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "seed_size = 100\n",
    "batch_size = 256\n",
    "gen_lr = 0.0003\n",
    "dis_lr = 0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seed = tf.random.normal(shape=(9, seed_size))\n",
    "ds = load_data(batch_size)\n",
    "gan_model = create_WGAN_GP(seed_size, gen_lr, dis_lr, dis_extra_steps=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%% ======= training ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 17s 71ms/step - dis_loss: -1.1909 - gen_loss: -7.4198\n",
      "Epoch 1/40\n",
      "  6/234 [..............................] - ETA: 21s - dis_loss: -1.1885 - gen_loss: -7.8823WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0373s vs `on_train_batch_end` time: 0.0509s). Check your callbacks.\n",
      "159/234 [===================>..........] - ETA: 5s - dis_loss: -1.0836 - gen_loss: -7.0922"
     ]
    }
   ],
   "source": [
    "shutil.rmtree('./tb_logs', ignore_errors=True)\n",
    "shutil.rmtree('./Results', ignore_errors=True)\n",
    "class GANMonitor(tf.keras.callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        if batch % 30 == 0:\n",
    "            generate_image(self.model, seed=test_seed, isShow=False, isSaveFile=True)\n",
    "        \n",
    "mon_cb = GANMonitor()\n",
    "save_cb = tf.keras.callbacks.ModelCheckpoint( './Checkpoints/', verbose=1)\n",
    "board_cb = tf.keras.callbacks.TensorBoard( log_dir='./tb_logs/', write_images=True, update_freq='epoch') \n",
    "gan_model.fit(ds, epochs=epochs, shuffle=True, callbacks=[mon_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%% ======= testing ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif():\n",
    "    with imageio.get_writer('./Results/result.gif', mode='I') as writer:\n",
    "        filenames = glob.glob('./Results/*.png')\n",
    "        filenames = sorted(filenames)\n",
    "        for filename in filenames:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "create_gif()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

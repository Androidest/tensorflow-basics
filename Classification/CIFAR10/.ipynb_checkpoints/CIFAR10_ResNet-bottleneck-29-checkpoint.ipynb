{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da98bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要添加一个新单元，输入 '# %%'\n",
    "# 要添加一个新的标记单元，输入 '# %% [markdown]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438cfdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== load data =============================\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.python.keras.backend import dropout\n",
    "\n",
    "classCount = 10\n",
    "batchSize = 512\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "                'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# random preview data augmentation effect\n",
    "def randShowGenImage(imGenerator):\n",
    "    [x, y] = imGenerator.next()\n",
    "    for i in range(len(y)):\n",
    "        img = x[i]\n",
    "        label = class_names[y[i]]\n",
    "        plt.figure(i)\n",
    "        plt.imshow(img)\n",
    "        plt.xlabel(label)\n",
    "\n",
    "def loadData(classCount, batchSize):\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "    (imgWidth, imgHeight, channels) = x_train[0].shape\n",
    "\n",
    "    imGenerator = tf.keras.preprocessing.image.ImageDataGenerator( \n",
    "        horizontal_flip=True,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        brightness_range=(0.5, 1.3),\n",
    "        # rescale=1./255,\n",
    "        rotation_range=12.0,\n",
    "        # shear_range=7.0,\n",
    "        zoom_range=(1,1.1),\n",
    "        fill_mode='constant',\n",
    "        cval=255.0, # constant value\n",
    "        data_format='channels_last', #(samples, height, width, channels)\n",
    "    )\n",
    "    imGenerator.fit(x_train)\n",
    "    mean = imGenerator.mean\n",
    "    std = imGenerator.std + 1e-07\n",
    "    print('mean: '+str(mean))\n",
    "    print('std: '+str(std))\n",
    "    imgNorm = lambda x: (x-mean)/std\n",
    "\n",
    "    # add a channel dimension: (n, imgHeight, imgWidth) -> (n, imgHeight, imgWidth, 1), channel=1 with grey-scale images\n",
    "    y_train = tf.reshape(y_train, shape=(len(y_train))).numpy()\n",
    "    train_gen = imGenerator.flow(x_train, y_train, batch_size=batchSize, shuffle=True)\n",
    "\n",
    "    x_test = imgNorm(x_test)\n",
    "    y_test = tf.reshape(y_test, shape=(len(y_test))).numpy()\n",
    "    ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(512)\n",
    "\n",
    "    return (train_gen, ds_test, imgNorm)\n",
    "\n",
    "(train_gen, ds_test, imgNorm) = loadData(classCount=classCount, batchSize=batchSize) \n",
    "# randShowGenImage(train_gen) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ad3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# tf.keras.applications.ResNet50V2\n",
    "# ==================== train & valid data =============================\n",
    "initial_epoch_batch = 0\n",
    "weight_decay = 0.0001\n",
    "max_learning_rate = 0.1\n",
    "\n",
    "def bn_relu(x, useRelu=True):\n",
    "    fx = layers.BatchNormalization()(x)\n",
    "    if useRelu:\n",
    "        fx = layers.ReLU()(fx)\n",
    "    return fx\n",
    "\n",
    "def conv(x, filterNumb, kernel_size, strides=1, use_bias=False):\n",
    "    fx = layers.Conv2D(filterNumb, kernel_size, strides, padding='same', use_bias=use_bias, kernel_regularizer=l2(weight_decay))(x)\n",
    "    return fx\n",
    "\n",
    "def sconv(x, filterNumb, kernel_size, strides=1, use_bias=True):\n",
    "    fx = layers.SeparableConv2D(filterNumb, kernel_size, strides, padding='same', use_bias=use_bias, kernel_regularizer=l2(weight_decay))(x)\n",
    "    return fx\n",
    "\n",
    "def bottleneck_res_block(x, filterNumb, type='identity', useRelu=True):\n",
    "    strides = 1\n",
    "    bn_x = bn_relu(x, useRelu=useRelu)\n",
    "\n",
    "    # different type of shortcut\n",
    "    if type is 'projection':\n",
    "        shortcut = conv(bn_x, 4 * filterNumb, kernel_size=3)\n",
    "    elif type is 'projection2':\n",
    "        shortcut = conv(bn_x, 4 * filterNumb, kernel_size=1)\n",
    "    elif type is 'pooling':\n",
    "        strides = 2\n",
    "        shortcut = layers.MaxPool2D(pool_size=(2,2), strides=strides)(x)\n",
    "    elif type is 'pooling2':\n",
    "        strides = 2\n",
    "        shortcut = conv(x, 4 * filterNumb, kernel_size=1, strides=strides)\n",
    "    else: # identity\n",
    "        shortcut = x # normal bottleneck\n",
    "    \n",
    "    fx = conv(bn_x, filterNumb, kernel_size=1)\n",
    "    fx = bn_relu(fx)\n",
    "    fx = conv(fx, filterNumb, kernel_size=3, strides=strides)\n",
    "    fx = bn_relu(fx)\n",
    "    fx = conv(fx, 4 * filterNumb, kernel_size=1)\n",
    "\n",
    "    out = layers.Add()([shortcut, fx]) # skip\n",
    "    return out\n",
    "\n",
    "def create_resnet():\n",
    "    inputs = layers.Input(shape=(32,32,3)) # 32*32\n",
    "    hx = bottleneck_res_block(inputs, 16, type='projection2', useRelu=False)\n",
    "    hx = bottleneck_res_block(hx, 16)\n",
    "    hx = bottleneck_res_block(hx, 16)\n",
    "    hx = bottleneck_res_block(hx, 16, type='pooling2') # 16*16\n",
    "\n",
    "    hx = bottleneck_res_block(hx, 32, type='projection2') \n",
    "    hx = bottleneck_res_block(hx, 32) \n",
    "    hx = bottleneck_res_block(hx, 32, type='pooling2') # 8*8\n",
    "\n",
    "    hx = bottleneck_res_block(hx, 64, type='projection2')\n",
    "    hx = bottleneck_res_block(hx, 64)\n",
    "    hx = bottleneck_res_block(hx, 64, type='pooling2') # 4*4\n",
    "\n",
    "    hx = bottleneck_res_block(hx, 128, type='projection2')\n",
    "    hx = bottleneck_res_block(hx, 128)\n",
    "    hx = bottleneck_res_block(hx, 128, type='pooling2') # 2*2\n",
    "\n",
    "    hx = bottleneck_res_block(hx, 256, type='projection2')\n",
    "    hx = bottleneck_res_block(hx, 256)\n",
    "\n",
    "    hx = bn_relu(hx)\n",
    "    hx = layers.GlobalAveragePooling2D()(hx)\n",
    "    outputs = layers.Dense(10)(hx)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "def display_history(history):\n",
    "    history = history.history\n",
    "    if len(history) == 0:\n",
    "        return\n",
    "    plt.figure(0)\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.show()\n",
    "\n",
    "if initial_epoch_batch == 0:\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    opt_fn = tf.keras.optimizers.Adam(max_learning_rate)\n",
    "    model = create_resnet()\n",
    "    model.compile(optimizer=opt_fn, loss=loss_fn, metrics=['accuracy'])\n",
    "else:\n",
    "    model = tf.keras.models.load_model('./Models/Checkpoint')\n",
    "    print(model.evaluate(x=ds_test, verbose=1))\n",
    "\n",
    "# start training\n",
    "def lr_scheduler(epoch, lr):\n",
    "    lr = max_learning_rate\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    return lr\n",
    "lr_cb = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "save_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    './Models/Checkpoint', monitor='val_accuracy', verbose=1, save_best_only=False,\n",
    "    save_weights_only=False, mode='max', save_freq='epoch'\n",
    ")\n",
    "\n",
    "ebatch = 20\n",
    "for i in range(initial_epoch_batch, 10):\n",
    "    history = model.fit(x=train_gen, epochs=(i+1)*ebatch, initial_epoch=i*ebatch, \n",
    "                        callbacks=[lr_cb, save_cb], workers=3,\n",
    "                        validation_data=ds_test, validation_freq=1, verbose=1)\n",
    "    display_history(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d24f9c3",
   "metadata": {
    "incorrectly_encoded_metadata": "===================================",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load best check point and save model\n",
    "import tensorflow as tf\n",
    "filePath = './Models/CIFAR10_ResNet-bottleneck-29.h5'\n",
    "model = tf.keras.models.load_model('./Models/Checkpoint')\n",
    "model.save(filePath, overwrite=True, include_optimizer=False)\n",
    "print(model.evaluate(x=ds_test, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20641e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== test with opencv =============================\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from common import videoCapture, screenCapture\n",
    "\n",
    "winName = 'CIFAR10 Classifier'\n",
    "canvasSize = 200\n",
    "outputSize = 32\n",
    "model = tf.keras.models.load_model('./Models/CIFAR10_ResNet-bottleneck-29.h5', compile=False)\n",
    "class_names = ['Plane', 'Car', 'Bird', 'Cat', 'Deer', \n",
    "                'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "\n",
    "def predict(frame):\n",
    "    img = tf.image.resize(frame, size=(outputSize, outputSize))\n",
    "    img = tf.reshape(img, shape=(1, outputSize, outputSize, 3))\n",
    "    predict = tf.argmax(model.predict(img), axis=1).numpy()[0]\n",
    "    result = np.copy(frame)\n",
    "    cv2.putText(result, str(class_names[predict]), (40,150), cv2.FONT_HERSHEY_COMPLEX, 1.3, (0,255,0), 2)\n",
    "    cv2.imshow(winName, result)\n",
    "\n",
    "\n",
    "# videoCapture(winName, canvasSize, canvasSize, predict)\n",
    "# screenCapture(winName, canvasSize, canvasSize, predict)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e879006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "incorrectly_encoded_metadata,-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

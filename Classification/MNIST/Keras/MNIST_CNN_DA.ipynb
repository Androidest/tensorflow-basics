{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要添加一个新单元，输入 '# %%'\n",
    "# 要添加一个新的标记单元，输入 '# %% [markdown]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449783e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# ==================== load data =============================\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "classCount = 10\n",
    "batchSize = 64\n",
    "\n",
    "def showNumbImage(x, y, numb):\n",
    "    numbArr = np.where(y == numb)[0]\n",
    "    index = numbArr[np.random.randint(0,len(numbArr))]\n",
    "    plt.imshow(x[index])\n",
    "\n",
    "def randShowGenImage(x, imGenerator):\n",
    "    img = x[np.random.randint(0,len(x))].numpy()\n",
    "    plt.figure()\n",
    "    plt.imshow(np.reshape(img, (28, 28)))\n",
    "    img = imGenerator.random_transform(x=img)\n",
    "    plt.figure()\n",
    "    plt.imshow(np.reshape(img, (28, 28)))\n",
    "\n",
    "def loadData(classCount, batchSize):\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    (imgWidth, imgHeight) = x_train[0].shape\n",
    "\n",
    "    imGenerator = tf.keras.preprocessing.image.ImageDataGenerator( \n",
    "        rotation_range=17.0, \n",
    "        width_shift_range=0.14,\n",
    "        height_shift_range=0.14,\n",
    "        shear_range=13.0,\n",
    "        zoom_range=(0.82,1.7),\n",
    "        fill_mode='constant', \n",
    "        cval=0.0, # value for points outside the img boundaries with fill_mode='constant'\n",
    "        data_format='channels_last' #(samples, height, width, channels)\n",
    "    )\n",
    "\n",
    "    # add a channel dimension: (60000, 28, 28) -> (60000, 28, 28, 1), channel=1 with grey-scale images\n",
    "    x_train = tf.reshape(x_train, shape=(-1, imgHeight, imgWidth, 1)) / 255\n",
    "    train_gen = imGenerator.flow(x_train, y_train, batch_size=batchSize, shuffle=True)\n",
    "\n",
    "    x_test = tf.reshape(x_test, shape=(-1, imgHeight, imgWidth, 1)) / 255\n",
    "    ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(2000)\n",
    "\n",
    "    # randShowGenImage(x_train, imGenerator) # random preview data augmentation effect\n",
    "\n",
    "    return (train_gen, ds_test)\n",
    "\n",
    "(train_gen, ds_test) = loadData(classCount=classCount, batchSize=batchSize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2179e96",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "# ==================== train & valid data =============================\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Conv 1\n",
    "    layers.Conv2D(32, kernel_size = 5, padding='same', activation='relu', input_shape=(28,28,1), data_format='channels_last'),\n",
    "    layers.BatchNormalization(),\n",
    "    # Strided Conv 1 (pooling layer)\n",
    "    layers.Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    # Conv 2\n",
    "    layers.Conv2D(64, kernel_size = 5, padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    # Strided Conv 1 (pooling layer)\n",
    "    layers.Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    # Fully connected\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "    # output \n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "# SparseCategoricalCrossentropy uses class indexes as labels not hot-one form\n",
    "# Replace standalone softmax layer with embeded softmax in loss function (using from_logits=True)\n",
    "# to prevent 0 inputs from softmax layer (0 input will lead error on cross-entropy)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "opt_fn = tf.keras.optimizers.Adam(0.001)\n",
    "lr_cb = tf.keras.callbacks.LearningRateScheduler(lambda epochIndex, lr: 0.001 * 0.96 ** epochIndex)\n",
    "save_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    './Models/Checkpoint', monitor='val_accuracy', verbose=1, save_best_only=True,\n",
    "    save_weights_only=False, mode='max', save_freq='epoch'\n",
    ")\n",
    "\n",
    "model.compile(optimizer=opt_fn, loss=loss_fn, metrics=['accuracy'])\n",
    "model.fit(x=train_gen, epochs=500, callbacks=[lr_cb, save_cb], \n",
    "            validation_data=ds_test, validation_freq=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaea3a6",
   "metadata": {
    "incorrectly_encoded_metadata": "===================================",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load best check point and save model\n",
    "import tensorflow as tf\n",
    "filePath = './Models/MNIST_CNN_new.h5'\n",
    "model = tf.keras.models.load_model('./Models/Checkpoint')\n",
    "model.save(filePath, overwrite=True, include_optimizer=False)\n",
    "model.evaluate(x=ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3df71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== test with opencv =============================\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "canvasSize = 300\n",
    "outputSize = 28\n",
    "penSize = 15\n",
    "\n",
    "isDrawing = False\n",
    "canvas = np.zeros((canvasSize, canvasSize, 3), np.uint8)\n",
    "model = tf.keras.models.load_model('./Models/MNIST_CNN_new.h5', compile=False)\n",
    "\n",
    "def draw(event, x, y, flags, param):\n",
    "    global canvas, isDrawing\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        isDrawing = True\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and isDrawing:\n",
    "        cv2.circle(canvas, (x,y), penSize, (255, 255, 255), -1)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        isDrawing = False\n",
    "        greyImg = tf.image.rgb_to_grayscale(tf.image.resize(canvas, size=(outputSize, outputSize)))\n",
    "        visualInput = tf.reshape(greyImg, shape=(1,28,28,1)) / 255\n",
    "        predict = tf.argmax(model.predict(visualInput), axis=1).numpy()[0]\n",
    "        result = np.zeros((canvasSize, canvasSize, 3), np.uint8)\n",
    "        cv2.putText(result, str(predict), (100,200), cv2.FONT_HERSHEY_COMPLEX, 6, (0,255,0), 25)\n",
    "        cv2.imshow('MNIST Result', result)\n",
    "    \n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        canvas = np.zeros((canvasSize, canvasSize, 3), np.uint8)\n",
    "\n",
    "cv2.namedWindow('MNIST Classifier')\n",
    "cv2.setMouseCallback('MNIST Classifier', draw)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('MNIST Classifier', canvas)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key != -1 and key != 255:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad600d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "incorrectly_encoded_metadata,-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

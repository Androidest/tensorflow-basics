{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777ccbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要添加一个新单元，输入 '# %%'\n",
    "# 要添加一个新的标记单元，输入 '# %% [markdown]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e6e15",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# ==================== load data =============================\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classCount = 10\n",
    "batchSize = 1000\n",
    "\n",
    "def load_2d_oneHot_dataset(classCount, batchSize):\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    (imgWidth, imgHeight) = x_train[0].shape\n",
    "    index = np.where(y_train == 7)[0][55]\n",
    "    plt.imshow(x_train[index])\n",
    "\n",
    "    # add a channel dimension: (60000, 28, 28) -> (60000, 28, 28, 1), channel=1 with grey-scale images\n",
    "    x_train = tf.reshape(x_train, shape=(-1, imgHeight, imgWidth, 1)) / 255 \n",
    "    y_train = tf.one_hot(y_train, classCount) # to one-hot form\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(1000).batch(batchSize)\n",
    "\n",
    "    x_test = tf.reshape(x_test, shape=(-1, imgHeight, imgWidth, 1)) / 255\n",
    "    y_test = tf.constant(y_test, dtype=tf.int32)  \n",
    "    ds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(2000)\n",
    "\n",
    "    return (ds_train, ds_test)\n",
    "\n",
    "(ds_train, ds_test) = load_2d_oneHot_dataset(classCount=classCount, batchSize=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2498db62",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# ==================== train & valid data =============================\n",
    "(_, imWidth, imHeight, channels) = ds_train.element_spec[0].shape   #batch shape: ((None, 28,28,1),(None, 10))\n",
    "\n",
    "# convolutional layers\n",
    "# 32 kinds of 5*5 kernels will be trained later, resulting 32 filtered images with the same size as source\n",
    "# 1th convolutional layer\n",
    "conv1_features = 32\n",
    "kernel_W1 = tf.Variable(tf.random.truncated_normal([5, 5, channels, conv1_features], stddev=0.1)) \n",
    "conv_b1 = tf.Variable(tf.zeros(shape=(conv1_features))) # one bias for each feature, add with broadcasting rule\n",
    "\n",
    "# 1th strided convolutional layer\n",
    "skernel_W1 = tf.Variable(tf.random.truncated_normal([5, 5, 1, conv1_features], stddev=0.1)) \n",
    "sconv_b1 = tf.Variable(tf.zeros(shape=(conv1_features))) # one bias for each feature, add with broadcasting rule\n",
    "\n",
    "# 2th convolutional layer\n",
    "conv2_features = 64\n",
    "kernel_W2 = tf.Variable(tf.random.truncated_normal([5, 5, conv1_features, conv2_features], stddev=0.1)) \n",
    "conv_b2 = tf.Variable(tf.zeros(shape=(conv2_features))) # one bias for each feature, add with broadcasting rule\n",
    "\n",
    "# 2th strided convolutional layer\n",
    "skernel_W2 = tf.Variable(tf.random.truncated_normal([5, 5, 1, conv2_features], stddev=0.1)) \n",
    "sconv_b2 = tf.Variable(tf.zeros(shape=(conv2_features))) # one bias for each feature, add with broadcasting rule\n",
    "\n",
    "# 3th convolutional layer\n",
    "conv3_features = 128\n",
    "kernel_W3 = tf.Variable(tf.random.truncated_normal([5, 5, conv2_features, conv3_features], stddev=0.1)) \n",
    "conv_b3 = tf.Variable(tf.zeros(shape=(conv3_features))) # one bias for each feature, add with broadcasting rule\n",
    "\n",
    "# 2th strided convolutional layer\n",
    "skernel_W3 = tf.Variable(tf.random.truncated_normal([5, 5, 1, conv3_features], stddev=0.1)) \n",
    "sconv_b3 = tf.Variable(tf.zeros(shape=(conv3_features)))\n",
    "\n",
    "# 4th convolutional layer\n",
    "kernel_W4 = tf.Variable(tf.random.truncated_normal([4, 4, conv3_features, classCount], stddev=0.1)) \n",
    "conv_b4 = tf.Variable(tf.zeros(shape=(classCount))) # one bias for each feature, add with broadcasting rule\n",
    "\n",
    "gradientDescent = tf.keras.optimizers.Adam(0.01) # smaller learning rate for stable learning\n",
    "\n",
    "@ tf.function\n",
    "def cnn_predict(img, isTraining=False):\n",
    "    # 1th convolutional layer\n",
    "    conv1 = tf.nn.conv2d(img, kernel_W1, strides=[1,1,1,1], padding='SAME') + conv_b1\n",
    "    conv1 = tf.nn.conv2d(conv1, skernel_W1, strides=[1,2,2,1], padding='SAME') + sconv_b1\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "    # 2th convolutional layer\n",
    "    conv2 = tf.nn.conv2d(conv1, kernel_W2, strides=[1,1,1,1], padding='SAME') + conv_b2\n",
    "    conv2 = tf.nn.conv2d(conv2, skernel_W2, strides=[1,2,2,1], padding='SAME') + sconv_b2\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "    # 3th convolutional layer\n",
    "    conv3 = tf.nn.conv2d(conv2, kernel_W3, strides=[1,1,1,1], padding='SAME') + conv_b3\n",
    "    conv3 = tf.nn.conv2d(conv3, skernel_W3, strides=[1,2,2,1], padding='SAME') + sconv_b3\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "\n",
    "    # 4th convolutional layer\n",
    "    conv4 = tf.nn.conv2d(conv3, kernel_W4, strides=[1,1,1,1], padding='SAME') + conv_b4\n",
    "    conv4 = tf.nn.relu(conv4)\n",
    "\n",
    "    # output layer\n",
    "    output = tf.nn.avg_pool2d(conv4, ksize=[1,4,4,1], strides=[1,1,1,1], padding='VALID')\n",
    "    output = tf.reshape(output, shape=[-1, 10])\n",
    "\n",
    "    if isTraining:\n",
    "        return tf.nn.softmax(output) # use softmax to highlight max value by using math, to simplify loss calculation\n",
    "\n",
    "    else:\n",
    "        return tf.argmax(output, axis=1, output_type=tf.int32)\n",
    "\n",
    "isFinished = False\n",
    "for epoch in range(1000):\n",
    "    batchIndex = 0\n",
    "    for batch in ds_train:\n",
    "        batchIndex += 1\n",
    "\n",
    "        # Train\n",
    "        (x, y_real) = batch  # y_real is ground truth in one-hot form\n",
    "        def loss():\n",
    "            y_predict = cnn_predict(x, isTraining=True) \n",
    "            # calculate loss using cross entropy\n",
    "            cross_entropy = -tf.math.reduce_sum(y_real * tf.math.log(y_predict)) # -Σ(y_real * log(y_predict))\n",
    "            return cross_entropy\n",
    "        gradientDescent.minimize(loss, var_list=[ kernel_W1, conv_b1, skernel_W1, sconv_b1, \n",
    "                                                  kernel_W2, conv_b2, skernel_W2, sconv_b2,\n",
    "                                                  kernel_W3, conv_b3, skernel_W3, sconv_b3,\n",
    "                                                  kernel_W4, conv_b4 ])\n",
    "\n",
    "        # Evaluate\n",
    "        if batchIndex % 10 == 0:\n",
    "            accuracy = 0\n",
    "            for batch in ds_test:\n",
    "                (x_test, y_test) = batch\n",
    "                y_predict = cnn_predict(x_test)\n",
    "                equality = tf.equal(y_test, y_predict)\n",
    "                accuracy += tf.reduce_mean(tf.cast(equality, tf.float32)).numpy() \n",
    "            accuracy /= len(ds_test)\n",
    "\n",
    "            print('Epoch:', epoch,', Batch:', batchIndex, 'Accuracy:', accuracy, flush=True)\n",
    "            if accuracy > 0.993:\n",
    "                isFinished = True\n",
    "                break\n",
    "        \n",
    "    if isFinished:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d911dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== test with opencv =============================\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "canvasSize = 300\n",
    "outputSize = 28\n",
    "penSize = 15\n",
    "\n",
    "isDrawing = False\n",
    "canvas = np.zeros((canvasSize, canvasSize, 3), np.uint8)\n",
    "\n",
    "def draw(event, x, y, flags, param):\n",
    "    global canvas, isDrawing\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        isDrawing = True\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and isDrawing:\n",
    "        cv2.circle(canvas, (x,y), penSize, (255, 255, 255), -1)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        isDrawing = False\n",
    "        greyImg = tf.image.rgb_to_grayscale(tf.image.resize(canvas, size=(outputSize, outputSize)))\n",
    "        visualInput = tf.reshape(greyImg, shape=(1, 28, 28, 1)) / 255\n",
    "        predict = cnn_predict(visualInput).numpy()[0]\n",
    "\n",
    "        result = np.zeros((canvasSize, canvasSize, 3), np.uint8)\n",
    "        cv2.putText(result, str(predict), (100,200), cv2.FONT_HERSHEY_COMPLEX, 6, (0,255,0), 25)\n",
    "        cv2.imshow('MNIST Result', result)\n",
    "        # print(predict.numpy())\n",
    "    \n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        canvas = np.zeros((canvasSize, canvasSize, 3), np.uint8)\n",
    "\n",
    "cv2.namedWindow('MNIST Classifier')\n",
    "cv2.setMouseCallback('MNIST Classifier', draw)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('MNIST Classifier', canvas)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key != -1 and key != 255:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc95b5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([[[[1,2,4]]],[[[1,2,4]]],[[[1,2,4]]]])\n",
    "a = tf.reshape(a, shape=[-1,3])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58906f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
